{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Exploring CRSP Data with Python\n",
    "\n",
    "This script demonstrates how to explore and analyze CRSP daily stock data using various Python plotting libraries.\n",
    "\n",
    "## Overview\n",
    "We'll analyze CRSP daily stock data for selected stocks (AAPL, JNJ, TSLA) and compare their performance against the S&P 500 index. The analysis includes:\n",
    "- Cumulative returns comparison\n",
    "- Dividend analysis\n",
    "- Rolling volatility analysis\n",
    "- Multiple plotting approaches (Matplotlib, Seaborn, Plotly)\n",
    "\n",
    "## Data Source\n",
    "- CRSP Daily Stock File v2 (DSF) via WRDS\n",
    "- Filtered for common stock universe with proper exchange and trading filters\n",
    "- Date range: 2019-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrds\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import config\n",
    "\n",
    "DATA_DIR = config.DATA_DIR\n",
    "WRDS_USERNAME = config.WRDS_USERNAME\n",
    "\n",
    "db = wrds.Connection(wrds_username=WRDS_USERNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding CRSP Data Structure\n",
    "\n",
    "To find the right table, we use a combination of the web query interface and the SAS Studio explorer.\n",
    "The web query interface is available at:\n",
    "https://wrds-www.wharton.upenn.edu/pages/get-data/center-research-security-prices-crsp/annual-update/stock-version-2/daily-stock-file/\n",
    "\n",
    "Note: Web queries often use merges of tables from many different sources. The results of these merges are not usually available through the Python API interface. Often, you'll have to merge the tables yourself.\n",
    "\n",
    "However, in this case, we can use the SAS Studio explorer to find the right table. Lucky for us, the data in the web query is available in a pre-merged table available through the Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's look at the standard daily stock file (DSF) from the CIZ format\n",
    "dsf = db.get_table(library=\"crsp\", table=\"dsf_v2\", obs=10)\n",
    "dsf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Pre-merged Table\n",
    "\n",
    "Now, let's find the pre-merged table that contains the data we want.\n",
    "Notice that it corresponds to the web query we used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db.get_table(library=\"crsp\", table=\"wrds_dsfv2_query\", obs=10)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We actually just made a mistake above. For some reason, we aren't allowed to access this via \"crspa\", but we are via \"crsp\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this now matches the web query variables list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Data Query\n",
    "\n",
    "Now, let's explore some of the columns. But first, we need to download more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    permno, \n",
    "    permco, \n",
    "    dlycaldt, \n",
    "    issuertype, \n",
    "    securitytype, \n",
    "    securitysubtype, \n",
    "    sharetype, \n",
    "    usincflg, \n",
    "    primaryexch, \n",
    "    conditionaltype, \n",
    "    tradingstatusflg,\n",
    "    dlyret, \n",
    "    dlyretx, \n",
    "    dlyreti,\n",
    "    dlyorddivamt,\n",
    "    dlynonorddivamt,\n",
    "    shrout, \n",
    "    dlyprc,\n",
    "    ticker,\n",
    "    securitynm,\n",
    "    sprtrn,\n",
    "    vwretd\n",
    "FROM \n",
    "    crsp.wrds_dsfv2_query\n",
    "WHERE \n",
    "    dlycaldt between '01/01/2019' and '01/01/2025' AND\n",
    "    sharetype = 'NS' AND\n",
    "    securitytype = 'EQTY' AND\n",
    "    securitysubtype = 'COM' AND\n",
    "    usincflg = 'Y' AND\n",
    "    issuertype IN ('ACOR', 'CORP') AND\n",
    "    primaryexch IN ('N', 'A', 'Q') AND\n",
    "    conditionaltype = 'RW' AND\n",
    "    tradingstatusflg = 'A'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_crsp_sample(data_dir=DATA_DIR):\n",
    "    \"\"\"\n",
    "    Pull CRSP daily stock data with comprehensive filtering for common stock universe.\n",
    "    \n",
    "    This function implements the equivalent of legacy CRSP filters:\n",
    "    - shrcd = 10 or 11 (common stock)\n",
    "    - exchcd = 1, 2, or 3 (NYSE, AMEX, NASDAQ)\n",
    "    \n",
    "    Filters applied:\n",
    "    1. Date range: 2019-2025\n",
    "    2. Common stock universe:\n",
    "       - sharetype = 'NS' (New Shares)\n",
    "       - securitytype = 'EQTY' (Equity)\n",
    "       - securitysubtype = 'COM' (Common Stock)\n",
    "       - usincflg = 'Y' (US Incorporated)\n",
    "       - issuertype IN ('ACOR', 'CORP') (Accordion or Corporate)\n",
    "    3. Exchange and trading filters:\n",
    "       - primaryexch IN ('N', 'A', 'Q') (NYSE, AMEX, NASDAQ)\n",
    "       - conditionaltype = 'RW' (Regular Way trading)\n",
    "       - tradingstatusflg = 'A' (Active trading status)\n",
    "    \n",
    "    Caching:\n",
    "    - Data is cached locally as a parquet file to avoid repeated WRDS queries\n",
    "    - If cached data exists, it loads from disk instead of querying WRDS\n",
    "    - If no cache exists, queries WRDS and saves the result for future use\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory to store/load cached data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Filtered CRSP daily stock data\n",
    "    \"\"\"\n",
    "    data_path = data_dir / \"crsp_dsf_v2_example.parquet\"\n",
    "    if data_path.exists():\n",
    "        df = pd.read_parquet(data_path)\n",
    "    else:\n",
    "        df = db.raw_sql(query, date_cols=[\"dlycaldt\"])\n",
    "        df.to_parquet(data_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pull_crsp_sample()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary and Exploration\n",
    "\n",
    "Let's look at some summary statistics to understand our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some summary statistics\n",
    "print(\"\\n=== Data Summary ===\")\n",
    "print(f\"Date range: {df['dlycaldt'].min()} to {df['dlycaldt'].max()}\")\n",
    "print(f\"Number of unique stocks: {df['permno'].nunique()}\")\n",
    "print(f\"Total observations: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Well-Known Stocks\n",
    "\n",
    "We'll look for stocks with recognizable tickers and good data coverage for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's identify some well-known stocks for analysis\n",
    "# We'll look for stocks with recognizable tickers and good data coverage\n",
    "stock_summary = df.groupby(['permno', 'ticker', 'securitynm']).agg({\n",
    "    'dlycaldt': ['count', 'min', 'max'],\n",
    "    'dlyret': 'count',\n",
    "    'dlyorddivamt': lambda x: (x > 0).sum()\n",
    "}).round(2)\n",
    "\n",
    "stock_summary.columns = ['obs_count', 'start_date', 'end_date', 'return_obs', 'dividend_days']\n",
    "stock_summary = stock_summary.reset_index()\n",
    "\n",
    "# Filter for stocks with good data coverage and recognizable names\n",
    "good_stocks = stock_summary[\n",
    "    (stock_summary['obs_count'] > 500) &  # At least 500 observations\n",
    "    (stock_summary['ticker'].notna()) &   # Has a ticker\n",
    "    (stock_summary['ticker'] != '')       # Ticker is not empty\n",
    "].sort_values('obs_count', ascending=False)\n",
    "\n",
    "print(\"\\n=== Top Stocks by Data Coverage ===\")\n",
    "good_stocks.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Stocks for Analysis\n",
    "\n",
    "Let's select three stocks for analysis:\n",
    "1. A dividend-paying stock (likely a utility or financial)\n",
    "2. A growth stock that pays no dividends (likely tech)\n",
    "3. A stock in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look for some specific well-known stocks\n",
    "target_tickers = ['AAPL', 'MSFT', 'JNJ', 'PG', 'KO', 'XOM', 'JPM', 'WMT', 'NVDA', 'TSLA']\n",
    "available_stocks = good_stocks[good_stocks['ticker'].isin(target_tickers)]\n",
    "\n",
    "print(\"\\n=== Available Target Stocks ===\")\n",
    "available_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select three stocks for analysis\n",
    "selected_stocks = ['AAPL', 'JNJ', 'TSLA']  # Apple (tech, some dividends), J&J (dividend payer), Tesla (no dividends)\n",
    "\n",
    "# Filter data for selected stocks and market\n",
    "selected_data = df[df['ticker'].isin(selected_stocks)].copy()\n",
    "market_data = df[['dlycaldt', 'sprtrn', 'vwretd']].drop_duplicates().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Check\n",
    "\n",
    "Let's verify our data quality and check for any duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check for duplicate dates in selected data\n",
    "print(f\"\\n=== Data Quality Check ===\")\n",
    "print(f\"Selected stocks data shape: {selected_data.shape}\")\n",
    "print(f\"Duplicate ticker-date combinations: {selected_data.duplicated(subset=['ticker', 'dlycaldt']).sum()}\")\n",
    "print(f\"Market data shape: {market_data.shape}\")\n",
    "print(f\"Duplicate dates in market data: {market_data.duplicated(subset=['dlycaldt']).sum()}\")\n",
    "\n",
    "# Show sample of selected data\n",
    "print(f\"\\nSample of selected data:\")\n",
    "print(selected_data[['ticker', 'dlycaldt', 'dlyret']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Cumulative Returns\n",
    "\n",
    "Now let's calculate cumulative returns for our selected stocks to analyze their performance over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cumulative_returns(data, return_col='dlyret'):\n",
    "    \"\"\"Calculate cumulative returns for each stock\"\"\"\n",
    "    data = data.copy()\n",
    "    data = data.sort_values(['ticker', 'dlycaldt'])\n",
    "    \n",
    "    # Handle potential duplicate dates by taking the last observation for each ticker-date combination\n",
    "    data = data.drop_duplicates(subset=['ticker', 'dlycaldt'], keep='last')\n",
    "    \n",
    "    # Calculate cumulative returns (1 + return) for each stock using a safer approach\n",
    "    data['cumret'] = 1.0  # Initialize with 1\n",
    "    \n",
    "    for ticker in data['ticker'].unique():\n",
    "        mask = data['ticker'] == ticker\n",
    "        returns = data.loc[mask, return_col].fillna(0)\n",
    "        cumulative = (1 + returns).cumprod()\n",
    "        data.loc[mask, 'cumret'] = cumulative\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative returns\n",
    "stock_cumret = calculate_cumulative_returns(selected_data)\n",
    "market_cumret = market_data.copy()\n",
    "market_cumret['cumret'] = (1 + market_cumret['sprtrn']).cumprod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 1: Matplotlib - Cumulative Returns Comparison\n",
    "\n",
    "Let's start with a traditional matplotlib plot to visualize the cumulative returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Matplotlib - Cumulative Returns Comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "for ticker in selected_stocks:\n",
    "    ticker_data = stock_cumret[stock_cumret['ticker'] == ticker]\n",
    "    plt.plot(ticker_data['dlycaldt'], ticker_data['cumret'], \n",
    "             label=ticker, linewidth=2, marker='o', markersize=3)\n",
    "\n",
    "# Add market portfolio\n",
    "plt.plot(market_cumret['dlycaldt'], market_cumret['cumret'], \n",
    "         label='S&P 500', linewidth=3, color='black', linestyle='--')\n",
    "\n",
    "plt.title('Cumulative Returns Comparison (2019-2025)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Cumulative Return (1 = $1 invested)', fontsize=12)\n",
    "plt.legend(fontsize=11, frameon=True, fancybox=True, shadow=True)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 2: Seaborn - Cumulative Returns with Better Styling\n",
    "\n",
    "Now let's use Seaborn for enhanced styling and aesthetics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Seaborn - Cumulative Returns with better styling\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Prepare data for seaborn\n",
    "plot_data = []\n",
    "for ticker in selected_stocks:\n",
    "    ticker_data = stock_cumret[stock_cumret['ticker'] == ticker][['dlycaldt', 'cumret']]\n",
    "    ticker_data['ticker'] = ticker\n",
    "    plot_data.append(ticker_data)\n",
    "\n",
    "# Add market data\n",
    "market_plot_data = market_cumret[['dlycaldt', 'cumret']].copy()\n",
    "market_plot_data['ticker'] = 'S&P 500'\n",
    "plot_data.append(market_plot_data)\n",
    "\n",
    "plot_df = pd.concat(plot_data, ignore_index=True)\n",
    "\n",
    "sns.lineplot(data=plot_df, x='dlycaldt', y='cumret', hue='ticker', \n",
    "             linewidth=2, markers=True, markersize=4)\n",
    "\n",
    "plt.title('Cumulative Returns: Selected Stocks vs S&P 500', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Cumulative Return', fontsize=12)\n",
    "plt.legend(title='Asset', fontsize=11)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 3: Plotly Express - Interactive Cumulative Returns\n",
    "\n",
    "Finally, let's create an interactive plot using Plotly Express for enhanced user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Plotly Express - Interactive Cumulative Returns\n",
    "fig = px.line(plot_df, x='dlycaldt', y='cumret', color='ticker',\n",
    "              title='Interactive Cumulative Returns Comparison',\n",
    "              labels={'dlycaldt': 'Date', 'cumret': 'Cumulative Return', 'ticker': 'Asset'},\n",
    "              line_shape='linear', render_mode='svg')\n",
    "\n",
    "fig.update_layout(\n",
    "    title_font_size=16,\n",
    "    xaxis_title_font_size=12,\n",
    "    yaxis_title_font_size=12,\n",
    "    legend_title_font_size=12,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividend Analysis\n",
    "\n",
    "Now let's analyze dividends to understand the income component of our selected stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's analyze dividends\n",
    "print(\"\\n=== Dividend Analysis ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cumulative_dividends(data):\n",
    "    \"\"\"Calculate cumulative dividends for each stock\"\"\"\n",
    "    data = data.copy()\n",
    "    data = data.sort_values(['ticker', 'dlycaldt'])\n",
    "    \n",
    "    # Handle potential duplicate dates by taking the last observation for each ticker-date combination\n",
    "    data = data.drop_duplicates(subset=['ticker', 'dlycaldt'], keep='last')\n",
    "    \n",
    "    # Sum up all dividend amounts (ordinary + non-ordinary)\n",
    "    data['total_div'] = data['dlyorddivamt'].fillna(0) + data['dlynonorddivamt'].fillna(0)\n",
    "    \n",
    "    # Calculate cumulative dividends using a safer approach\n",
    "    data['cumdiv'] = 0.0  # Initialize with 0\n",
    "    \n",
    "    for ticker in data['ticker'].unique():\n",
    "        mask = data['ticker'] == ticker\n",
    "        dividends = data.loc[mask, 'total_div']\n",
    "        cumulative = dividends.cumsum()\n",
    "        data.loc[mask, 'cumdiv'] = cumulative\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative dividends\n",
    "stock_cumdiv = calculate_cumulative_dividends(selected_data)\n",
    "\n",
    "# Get dividend summary\n",
    "div_summary = stock_cumdiv.groupby('ticker').agg({\n",
    "    'total_div': ['sum', 'count'],\n",
    "    'cumdiv': 'max'\n",
    "}).round(4)\n",
    "\n",
    "div_summary.columns = ['total_dividends', 'dividend_days', 'cumulative_dividends']\n",
    "print(div_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 4: Matplotlib - Cumulative Dividends\n",
    "\n",
    "Let's visualize the cumulative dividends using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 4: Matplotlib - Cumulative Dividends\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for ticker in selected_stocks:\n",
    "    ticker_data = stock_cumdiv[stock_cumdiv['ticker'] == ticker]\n",
    "    plt.plot(ticker_data['dlycaldt'], ticker_data['cumdiv'], \n",
    "             label=f'{ticker} (Total: ${ticker_data[\"cumdiv\"].max():.2f})', \n",
    "             linewidth=2, marker='s', markersize=3)\n",
    "\n",
    "plt.title('Cumulative Dividends Paid (2019-2025)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Cumulative Dividends ($)', fontsize=12)\n",
    "plt.legend(fontsize=11, frameon=True, fancybox=True, shadow=True)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 5: Seaborn - Dividend Comparison\n",
    "\n",
    "Now let's use Seaborn for the dividend visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 5: Seaborn - Dividend Comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Prepare dividend data for seaborn\n",
    "div_plot_data = []\n",
    "for ticker in selected_stocks:\n",
    "    ticker_data = stock_cumdiv[stock_cumdiv['ticker'] == ticker][['dlycaldt', 'cumdiv']]\n",
    "    ticker_data['ticker'] = ticker\n",
    "    div_plot_data.append(ticker_data)\n",
    "\n",
    "div_plot_df = pd.concat(div_plot_data, ignore_index=True)\n",
    "\n",
    "sns.lineplot(data=div_plot_df, x='dlycaldt', y='cumdiv', hue='ticker', \n",
    "             linewidth=2, markers=True, markersize=4)\n",
    "\n",
    "plt.title('Cumulative Dividends: Selected Stocks', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Cumulative Dividends ($)', fontsize=12)\n",
    "plt.legend(title='Stock', fontsize=11)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 6: Plotly Express - Interactive Dividends\n",
    "\n",
    "Let's create an interactive dividend plot with Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 6: Plotly Express - Interactive Dividends\n",
    "fig = px.line(div_plot_df, x='dlycaldt', y='cumdiv', color='ticker',\n",
    "              title='Interactive Cumulative Dividends',\n",
    "              labels={'dlycaldt': 'Date', 'cumdiv': 'Cumulative Dividends ($)', 'ticker': 'Stock'},\n",
    "              line_shape='linear', render_mode='svg')\n",
    "\n",
    "fig.update_layout(\n",
    "    title_font_size=16,\n",
    "    xaxis_title_font_size=12,\n",
    "    yaxis_title_font_size=12,\n",
    "    legend_title_font_size=12,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Volatility Analysis\n",
    "\n",
    "Now let's analyze the rolling volatility of our selected stocks to understand their risk characteristics over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate rolling volatility (3-month window)\n",
    "print(\"\\n=== Rolling Volatility Analysis ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_volatility(data, window_days=63):  # ~3 months (63 trading days)\n",
    "    \"\"\"Calculate rolling volatility for each stock\"\"\"\n",
    "    data = data.copy()\n",
    "    data = data.sort_values(['ticker', 'dlycaldt'])\n",
    "    \n",
    "    # Handle potential duplicate dates by taking the last observation for each ticker-date combination\n",
    "    data = data.drop_duplicates(subset=['ticker', 'dlycaldt'], keep='last')\n",
    "    \n",
    "    # Calculate rolling standard deviation of returns using a safer approach\n",
    "    data['rolling_vol'] = np.nan\n",
    "    data['rolling_vol_annual'] = np.nan\n",
    "    \n",
    "    for ticker in data['ticker'].unique():\n",
    "        mask = data['ticker'] == ticker\n",
    "        returns = data.loc[mask, 'dlyret'].fillna(0)\n",
    "        \n",
    "        # Calculate rolling standard deviation\n",
    "        rolling_std = returns.rolling(window=window_days, min_periods=30).std()\n",
    "        data.loc[mask, 'rolling_vol'] = rolling_std\n",
    "        \n",
    "        # Annualize volatility (multiply by sqrt(252) for daily data)\n",
    "        data.loc[mask, 'rolling_vol_annual'] = rolling_std * np.sqrt(252)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling volatility for stocks\n",
    "stock_vol = calculate_rolling_volatility(selected_data)\n",
    "\n",
    "# Calculate rolling volatility for market\n",
    "market_vol = market_data.copy()\n",
    "market_vol['rolling_vol'] = market_vol['sprtrn'].rolling(\n",
    "    window=63, min_periods=30\n",
    ").std()\n",
    "market_vol['rolling_vol_annual'] = market_vol['rolling_vol'] * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 7: Matplotlib - Rolling Volatility\n",
    "\n",
    "Let's visualize the rolling volatility using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 7: Matplotlib - Rolling Volatility\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for ticker in selected_stocks:\n",
    "    ticker_data = stock_vol[stock_vol['ticker'] == ticker]\n",
    "    plt.plot(ticker_data['dlycaldt'], ticker_data['rolling_vol_annual'] * 100, \n",
    "             label=ticker, linewidth=2, alpha=0.8)\n",
    "\n",
    "# Add market volatility\n",
    "plt.plot(market_vol['dlycaldt'], market_vol['rolling_vol_annual'] * 100, \n",
    "         label='S&P 500', linewidth=3, color='black', linestyle='--')\n",
    "\n",
    "plt.title('Rolling 3-Month Volatility (Annualized)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Volatility (%)', fontsize=12)\n",
    "plt.legend(fontsize=11, frameon=True, fancybox=True, shadow=True)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 8: Seaborn - Volatility Comparison\n",
    "\n",
    "Now let's use Seaborn for the volatility visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 8: Seaborn - Volatility Comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Prepare volatility data for seaborn\n",
    "vol_plot_data = []\n",
    "for ticker in selected_stocks:\n",
    "    ticker_data = stock_vol[stock_vol['ticker'] == ticker][['dlycaldt', 'rolling_vol_annual']]\n",
    "    ticker_data['ticker'] = ticker\n",
    "    vol_plot_data.append(ticker_data)\n",
    "\n",
    "# Add market volatility\n",
    "market_vol_data = market_vol[['dlycaldt', 'rolling_vol_annual']].copy()\n",
    "market_vol_data['ticker'] = 'S&P 500'\n",
    "vol_plot_data.append(market_vol_data)\n",
    "\n",
    "vol_plot_df = pd.concat(vol_plot_data, ignore_index=True)\n",
    "vol_plot_df['rolling_vol_annual'] = vol_plot_df['rolling_vol_annual'] * 100  # Convert to percentage\n",
    "\n",
    "sns.lineplot(data=vol_plot_df, x='dlycaldt', y='rolling_vol_annual', hue='ticker', \n",
    "             linewidth=2, alpha=0.8)\n",
    "\n",
    "plt.title('Rolling 3-Month Volatility: Stocks vs S&P 500', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Volatility (%)', fontsize=12)\n",
    "plt.legend(title='Asset', fontsize=11)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 9: Plotly Express - Interactive Volatility\n",
    "\n",
    "Finally, let's create an interactive volatility plot with Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 9: Plotly Express - Interactive Volatility\n",
    "fig = px.line(vol_plot_df, x='dlycaldt', y='rolling_vol_annual', color='ticker',\n",
    "              title='Interactive Rolling Volatility Analysis',\n",
    "              labels={'dlycaldt': 'Date', 'rolling_vol_annual': 'Volatility (%)', 'ticker': 'Asset'},\n",
    "              line_shape='linear', render_mode='svg')\n",
    "\n",
    "fig.update_layout(\n",
    "    title_font_size=16,\n",
    "    xaxis_title_font_size=12,\n",
    "    yaxis_title_font_size=12,\n",
    "    legend_title_font_size=12,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Let's compile a comprehensive summary of our analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "print(\"Cumulative Returns (as of latest date):\")\n",
    "for ticker in selected_stocks:\n",
    "    latest_ret = stock_cumret[stock_cumret['ticker'] == ticker]['cumret'].iloc[-1]\n",
    "    print(f\"{ticker}: {latest_ret:.2f}x\")\n",
    "\n",
    "latest_market_ret = market_cumret['cumret'].iloc[-1]\n",
    "print(f\"S&P 500: {latest_market_ret:.2f}x\")\n",
    "\n",
    "print(\"\\nTotal Dividends Paid:\")\n",
    "for ticker in selected_stocks:\n",
    "    total_div = stock_cumdiv[stock_cumdiv['ticker'] == ticker]['cumdiv'].iloc[-1]\n",
    "    print(f\"{ticker}: ${total_div:.2f}\")\n",
    "\n",
    "print(\"\\nAverage Annualized Volatility (3-month rolling):\")\n",
    "for ticker in selected_stocks:\n",
    "    avg_vol = stock_vol[stock_vol['ticker'] == ticker]['rolling_vol_annual'].mean() * 100\n",
    "    print(f\"{ticker}: {avg_vol:.1f}%\")\n",
    "\n",
    "avg_market_vol = market_vol['rolling_vol_annual'].mean() * 100\n",
    "print(f\"S&P 500: {avg_market_vol:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Complete\n",
    "\n",
    "This script demonstrates:\n",
    "1. Matplotlib plotting with pyplot interface\n",
    "2. Seaborn plotting with enhanced styling\n",
    "3. Plotly Express for interactive visualizations\n",
    "4. Cumulative return analysis for selected stocks vs S&P 500\n",
    "5. Dividend analysis comparing dividend-paying vs non-dividend stocks\n",
    "6. Rolling volatility analysis using 3-month windows\n",
    "\n",
    "The analysis provides insights into:\n",
    "- Performance comparison between different types of stocks\n",
    "- Income generation through dividends\n",
    "- Risk characteristics over time\n",
    "- Interactive visualization capabilities for data exploration\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n=== Analysis Complete ===\")\n",
    "print(\"This script demonstrates:\")\n",
    "print(\"1. Matplotlib plotting with pyplot interface\")\n",
    "print(\"2. Seaborn plotting with enhanced styling\")\n",
    "print(\"3. Plotly Express for interactive visualizations\")\n",
    "print(\"4. Cumulative return analysis for selected stocks vs S&P 500\")\n",
    "print(\"5. Dividend analysis comparing dividend-paying vs non-dividend stocks\")\n",
    "print(\"6. Rolling volatility analysis using 3-month windows\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
